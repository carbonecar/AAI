{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller Práctico: Árboles de Decisión con Scikit-Learn\n",
    "\n",
    "**Objetivos de la Práctica:**\n",
    "\n",
    "En este taller, aplicaremos los conceptos teóricos de los árboles de decisión. Al finalizar, serás capaz de:\n",
    "\n",
    "1.  **Cargar y preparar datos** para un problema de clasificación.\n",
    "2.  **Entrenar un árbol de decisión** utilizando la librería `scikit-learn`.\n",
    "3.  **Visualizar e interpretar** la estructura de un árbol.\n",
    "4.  Identificar y comprender el problema del **sobreajuste** en los árboles.\n",
    "5.  Aplicar la **poda por complejidad de costo** para encontrar un árbol más robusto.\n",
    "6.  Evaluar la **importancia de las características** que el modelo aprende."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparación del Entorno\n",
    "\n",
    "Primero, importaremos las librerías que necesitaremos para nuestro análisis. Usaremos `pandas` para la manipulación de datos, `scikit-learn` para el modelado, `plotly` para visualizaciones interactivas y `matplotlib` para la visualización específica del árbol."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Librerías para manipulación y análisis de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librerías para modelado y evaluación\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Librerías para visualización\n",
    "import plotly.express as px\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Exploración de Datos\n",
    "\n",
    "Vamos a utilizar el dataset de **Cáncer de Mama de Wisconsin**, que está convenientemente incluido en `scikit-learn`. Es un problema de clasificación binaria clásico donde el objetivo es predecir si un tumor es maligno o benigno basándose en varias características de sus células."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cargamos el dataset. `as_frame=True` nos lo devuelve como un DataFrame de pandas.\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "# Separamos las características (X) y la variable objetivo (y)\n",
    "X = df[data.feature_names]\n",
    "y = df['target']\n",
    "\n",
    "# Nombres de las clases (0: Maligno, 1: Benigno)\n",
    "print(f\"Nombres de las clases: {data.target_names}\")\n",
    "\n",
    "# Echamos un vistazo a las primeras filas del dataset\n",
    "print(\"\\nPrimeras 5 filas de características:\")\n",
    "display(X.head())\n",
    "\n",
    "# Resumen del dataset\n",
    "print(\"\\nInformación del DataFrame:\")\n",
    "X.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y.value_counts().plot(kind='bar', title='Distribución de Clases')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización Exploratoria\n",
    "Usemos Plotly para visualizar la relación entre dos características importantes, `mean radius` y `mean texture`, y ver cómo se distribuyen las clases."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_to_plot = df.copy()\n",
    "df_to_plot['target'] = df_to_plot['target'].map({i: name for i, name in enumerate(data.target_names)})\n",
    "fig = px.scatter(\n",
    "    df_to_plot,\n",
    "    x='mean radius', \n",
    "    y='mean texture', \n",
    "    color='target', \n",
    "    #color_continuous_scale='reds_r',\n",
    "    title='Distribución de Clases por Radio y Textura Promedio',\n",
    "    labels={'target': 'Clase', 'mean radius': 'Radio Promedio', 'mean texture': 'Textura Promedia'}\n",
    ")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento de un Árbol de Decisión (Sin Poda)\n",
    "\n",
    "Ahora, dividiremos nuestros datos en un conjunto de entrenamiento y uno de prueba. Luego, entrenaremos un árbol de decisión sin ninguna restricción de crecimiento para observar el fenómeno del sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Dividimos los datos: 80% para entrenamiento, 20% para prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creamos el clasificador sin restricciones de profundidad\n",
    "tree_overfit = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "tree_overfit.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos el rendimiento\n",
    "y_train_pred = tree_overfit.predict(X_train)\n",
    "y_test_pred = tree_overfit.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Precisión en el set de ENTRENAMIENTO: {train_accuracy:.4f}\")\n",
    "print(f\"Precisión en el set de PRUEBA: {test_accuracy:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Observación:** ¡El modelo tiene una precisión del 100% en los datos de entrenamiento! Esto es una señal clara de sobreajuste. El árbol ha crecido tanto que ha \"memorizado\" cada punto de entrenamiento, pero su rendimiento en los datos de prueba, aunque bueno, es menor."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización del Árbol Sobreajustado\n",
    "Veamos qué tan complejo es este árbol. La función `plot_tree` nos ayuda a visualizarlo. Usamos `matplotlib` para esta tarea, ya que `plot_tree` está construida sobre ella."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "plot_tree(tree_overfit, \n",
    "          feature_names=data.feature_names, \n",
    "          class_names=data.target_names, \n",
    "          filled=True,\n",
    "          fontsize=8)\n",
    "plt.title(\"Árbol de Decisión Sin Poda (Sobreajustado)\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, el árbol es enorme e ininterpretable. Necesitamos una forma de simplificarlo: la poda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Poda por Complejidad de Costo (Cost-Complexity Pruning)\n",
    "\n",
    "La poda por complejidad de costo es una estrategia para encontrar el sub-árbol que mejor generaliza. Funciona penalizando el tamaño del árbol. El parámetro clave es `ccp_alpha` (el $\\alpha$ que vimos en la teoría).\n",
    "\n",
    "El proceso es:\n",
    "1.  Calcular la ruta de poda: obtener los valores de `ccp_alpha` que generan diferentes sub-árboles.\n",
    "2.  Usar validación cruzada para encontrar el mejor valor de `ccp_alpha`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1. Calcular la ruta de poda\n",
    "path = tree_overfit.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Excluimos el alpha máximo que eliminaría todo el árbol\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "# 2. Encontrar el mejor alpha con Validación Cruzada\n",
    "param_grid = {'ccp_alpha': ccp_alphas}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_alpha = grid_search.best_params_['ccp_alpha']\n",
    "print(f\"Mejor valor de ccp_alpha encontrado: {best_alpha:.6f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento y Evaluación del Árbol Óptimo\n",
    "\n",
    "Ahora que tenemos el mejor valor de `ccp_alpha`, entrenamos un nuevo árbol con ese parámetro y evaluamos su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# El GridSearchCV con refit=True (por defecto) ya ha re-entrenado el mejor modelo\n",
    "tree_pruned = grid_search.best_estimator_\n",
    "\n",
    "# Evaluamos el nuevo modelo podado\n",
    "y_train_pred_p = tree_pruned.predict(X_train)\n",
    "y_test_pred_p = tree_pruned.predict(X_test)\n",
    "\n",
    "train_accuracy_p = accuracy_score(y_train, y_train_pred_p)\n",
    "test_accuracy_p = accuracy_score(y_test, y_test_pred_p)\n",
    "\n",
    "print(\"--- Árbol Sobreajustado ---\")\n",
    "print(f\"Precisión en Entrenamiento: {train_accuracy:.4f}\")\n",
    "print(f\"Precisión en Prueba: {test_accuracy:.4f}\")\n",
    "print(\"\\n--- Árbol Podado ---\")\n",
    "print(f\"Precisión en Entrenamiento: {train_accuracy_p:.4f}\")\n",
    "print(f\"Precisión en Prueba: {test_accuracy_p:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de Resultados:** El árbol podado tiene una precisión de entrenamiento más baja (ya no es 100%), lo cual es bueno, significa que no está memorizando. Sin embargo, su precisión en el conjunto de prueba es mayor. ¡Hemos creado un modelo más simple y que generaliza mejor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización del Árbol Podado\n",
    "Veamos ahora nuestro nuevo árbol, mucho más simple e interpretable."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(tree_pruned, \n",
    "          feature_names=data.feature_names, \n",
    "          class_names=data.target_names, \n",
    "          filled=True,\n",
    "          fontsize=10)\n",
    "plt.title(\"Árbol de Decisión Podado con ccp_alpha Óptimo\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Importancia de las Características\n",
    "\n",
    "Finalmente, podemos extraer qué características consideró más importantes nuestro árbol podado para tomar sus decisiones. Esto se basa en la reducción total del índice de Gini que cada característica aporta.\n",
    "\n",
    "La importancia de las características en los árboles de decisión se calcula midiendo cuánto reduce cada característica la impureza (como la impureza de Gini o la entropía) en todos los nodos donde se utiliza para dividir los datos. La importancia de cada característica es la suma de las reducciones de impureza que aporta, ponderada por la cantidad de muestras que divide, y normalizada para que todas las importancias sumen 1."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "importances = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': tree_pruned.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "fig = px.bar(\n",
    "    importances,\n",
    "    x='feature',\n",
    "    y='importance',\n",
    "    title='Importancia de las Características en el Árbol Podado',\n",
    "    labels={'feature': 'Característica', 'importance': 'Importancia (Reducción de Gini)'}\n",
    ")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Desafíos y Experimentación 🚀\n",
    "\n",
    "Ahora es tu turno de experimentar. Intenta responder a las siguientes preguntas modificando el código anterior:\n",
    "\n",
    "1.  **Cambia el Criterio:** En lugar de `'gini'`, entrena un árbol usando `'entropy'` como criterio. ¿Cambia mucho el árbol podado final? ¿Y la importancia de las características?\n",
    "2.  **Poda por Profundidad:** En lugar de usar `ccp_alpha`, intenta controlar el sobreajuste con el hiperparámetro `max_depth`. Usa `GridSearchCV` para encontrar la profundidad óptima. ¿Qué método da mejores resultados en el set de prueba: poda por complejidad o por profundidad máxima?\n",
    "3.  **Estabilidad del Modelo:** Cambia el `random_state` en `train_test_split` a otro número (o quítalo). Vuelve a correr todo el notebook. ¿El árbol final y la precisión cambian mucho? Esto te dará una idea de la inestabilidad de los árboles de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📝 Ejercicios Adicionales\n",
    "\n",
    "Para solidificar tu aprendizaje, te proponemos los siguientes ejercicios para que explores por tu cuenta:\n",
    "\n",
    "1.  **Otro Dataset de Clasificación:** Repite el análisis completo de este notebook (entrenamiento, poda, visualización) pero con el dataset de **Vinos** de `scikit-learn` (`sklearn.datasets.load_wine`). Es un problema con 3 clases.\n",
    "\n",
    "2.  **Árboles de Regresión:** Importa el dataset de **Viviendas de California** (`sklearn.datasets.fetch_california_housing`). Entrena un `DecisionTreeRegressor` para predecir el valor de las viviendas. El criterio de división por defecto es el error cuadrático medio (`'squared_error'`). ¿Cómo interpretas el árbol resultante?\n",
    "\n",
    "3.  **Análisis de Hiperparámetros:** Investiga el efecto de `min_samples_split` y `min_samples_leaf`. Usa `GridSearchCV` para encontrar la mejor combinación de `max_depth`, `min_samples_split` y `min_samples_leaf` para el dataset de cáncer. ¿Mejora el resultado de la poda por complejidad?\n",
    "\n",
    "4.  **Visualización de Fronteras de Decisión:** Usando solo dos características (ej. `mean radius` y `mean texture`), entrena un árbol simple (ej. `max_depth=3`). Investiga cómo crear un gráfico de contorno (contour plot) para visualizar las \"cajas\" o fronteras de decisión que el árbol crea en el espacio 2D.\n",
    "\n",
    "5.  **Sensibilidad a la Escala:** Aunque se dijo que los árboles no son sensibles a la escala, compruébalo. Aplica un `StandardScaler` de `scikit-learn` a los datos `X` antes de entrenar el árbol. ¿Cambia la estructura del árbol o su rendimiento? ¿Por qué sí o por qué no?\n",
    "\n",
    "6.  **Interpreta una Ruta de Decisión:** En el árbol podado final, elige una hoja y traza la ruta desde el nodo raíz hasta ella. Escribe en texto plano la secuencia de reglas que definen esa hoja. (Ej: \"Si `worst radius <= 16.5` Y `worst concave points <= 0.142`...\").\n",
    "\n",
    "7.  **Comparación de Métricas de Impureza:** En el árbol podado con Gini, anota la importancia de las 5 características principales. Ahora, fuerza el entrenamiento y la poda usando `'entropy'` como criterio. Compara la nueva lista de las 5 características más importantes. ¿Son las mismas? ¿En el mismo orden?\n",
    "\n",
    "8.  **Efecto del Tamaño del Test Set:** Vuelve a ejecutar el análisis, pero esta vez con `test_size=0.4`. ¿Cómo afecta un conjunto de prueba más grande a la evaluación del rendimiento y a la confianza que tienes en tu modelo?\n",
    "\n",
    "9.  **Explora la Salida de `cost_complexity_pruning_path`:** La variable `path` que creamos contiene `ccp_alphas` e `impurities`. Grafica `impurities` vs `ccp_alphas`. ¿Qué te dice este gráfico sobre cómo la pureza del árbol se ve afectada por el parámetro de poda?\n",
    "\n",
    "10. **Impacto de una Característica Ruidosa:** Añade una nueva columna a `X_train` y `X_test` con datos completamente aleatorios (ej. `np.random.rand(n_samples, 1)`). Vuelve a entrenar el modelo y a calcular la importancia de características. ¿Aparece la nueva característica \"ruidosa\" como importante? ¿Qué te dice esto sobre los árboles?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
