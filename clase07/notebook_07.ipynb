{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 7: Taller Práctico - Otros Métodos Supervisados\n",
    "\n",
    "**Objetivos:**\n",
    "\n",
    "En este taller, aplicaremos y compararemos los tres métodos de clasificación que hemos estudiado en la clase teórica:\n",
    "\n",
    "1.  **k-Nearest Neighbors (k-NN)**: Un clasificador basado en instancia y distancia.\n",
    "2.  **Naive Bayes**: Un clasificador probabilístico basado en el teorema de Bayes.\n",
    "3.  **Perceptrón Multicapa (MLP)**: Nuestro primer vistazo a una red neuronal simple.\n",
    "\n",
    "Utilizaremos el conjunto de datos \"Wine\" de Scikit-learn, un dataset clásico para problemas de clasificación multiclase. El objetivo es clasificar vinos en una de tres categorías basándonos en sus atributos químicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuración Inicial e Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Librerías para manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "# Librerías de Scikit-learn para el modelado\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Librerías para visualización\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Exploración del Dataset (EDA)\n",
    "\n",
    "El dataset \"Wine\" contiene los resultados de un análisis químico de vinos cultivados en la misma región en Italia pero derivados de tres cultivares diferentes. El análisis determinó las cantidades de 13 constituyentes encontrados en cada uno de los tres tipos de vinos."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cargar el dataset\n",
    "wine_data = load_wine()\n",
    "X = pd.DataFrame(wine_data.data, columns=wine_data.feature_names)\n",
    "y = pd.Series(wine_data.target, name='target')\n",
    "\n",
    "# Unir características y objetivo en un solo DataFrame para exploración\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Mapear los números del objetivo a nombres de clases para mayor claridad\n",
    "df['target_name'] = df['target'].map({0: 'Class_0', 1: 'Class_1', 2: 'Class_2'})\n",
    "\n",
    "print(\"Primeras 5 filas del dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nDescripción estadística de las características:\")\n",
    "display(df.describe())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización con PCA\n",
    "\n",
    "Dado que tenemos 13 características, no podemos visualizarlas todas a la vez. Usaremos el Análisis de Componentes Principales (PCA) para reducir la dimensionalidad a 2 componentes y visualizar la separación de las clases."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Primero, escalamos los datos para que PCA funcione correctamente\n",
    "scaler_pca = StandardScaler()\n",
    "X_scaled_pca = scaler_pca.fit_transform(X)\n",
    "\n",
    "# Aplicamos PCA para reducir a 2 dimensiones\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled_pca)\n",
    "\n",
    "# Creamos un DataFrame para la visualización\n",
    "df_pca = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\n",
    "df_pca['target_name'] = df['target_name']\n",
    "\n",
    "# Gráfico interactivo con Plotly\n",
    "fig = px.scatter(df_pca, \n",
    "                 x='PC1', \n",
    "                 y='PC2', \n",
    "                 color='target_name', \n",
    "                 title='Visualización del Dataset Wine con PCA (2 Componentes)',\n",
    "                 labels={'PC1': 'Primer Componente Principal', 'PC2': 'Segundo Componente Principal'},\n",
    "                 template='plotly_white')\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "La visualización PCA nos muestra que las clases están razonablemente bien separadas, aunque con algo de superposición. Esto sugiere que los algoritmos de clasificación deberían poder encontrar patrones útiles."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparación de los Datos para el Modelado\n",
    "\n",
    "Ahora, dividiremos los datos en conjuntos de entrenamiento y prueba, y aplicaremos el escalado de características. El escalado es fundamental para k-NN y MLP, ya que son sensibles a las diferentes escalas de las variables."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Separar los datos originales (sin PCA) en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Inicializar el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar el escalador SÓLO con los datos de entrenamiento\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Aplicar la misma transformación a los datos de prueba\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Tamaño del set de entrenamiento: {X_train_scaled.shape[0]} muestras\")\n",
    "print(f\"Tamaño del set de prueba: {X_test_scaled.shape[0]} muestras\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementación y Evaluación de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1: k-Nearest Neighbors (k-NN)\n",
    "\n",
    "Implementaremos k-NN con un valor de `k` inicial (ej. k=5) y evaluaremos su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "# Inicializar y entrenar el clasificador k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"------ Resultados de k-NN (k=5) ------\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_knn):.4f}\")\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "end = time.time()\n",
    "print(f\"{end - start:.3f} segundos para entrenar el modelo k-NN\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío: Encontrar el `k` Óptimo\n",
    "\n",
    "El rendimiento de k-NN depende fuertemente del valor de `k`. Un `k` muy pequeño puede llevar a sobreajuste, mientras que un `k` muy grande puede simplificar demasiado el modelo. \n",
    "\n",
    "**Tu tarea:** Escribe un bucle que entrene y evalúe el modelo k-NN para un rango de valores de `k` (por ejemplo, de 1 a 30). Almacena la precisión (accuracy) para cada `k` y luego crea un gráfico para visualizar cómo cambia la precisión en función de `k`. ¿Cuál es el valor de `k` que da el mejor resultado en el conjunto de prueba?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Espacio para tu solución al desafío\n",
    "k_values = range(1, 31)\n",
    "accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn_loop = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_loop.fit(X_train_scaled, y_train)\n",
    "    y_pred_loop = knn_loop.predict(X_test_scaled)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred_loop))\n",
    "\n",
    "# Gráfico de k vs. Accuracy\n",
    "fig = go.Figure(data=go.Scatter(x=list(k_values), y=accuracies, mode='lines+markers'))\n",
    "fig.update_layout(\n",
    "    title='Accuracy de k-NN en función del número de vecinos (k)',\n",
    "    xaxis_title='Valor de k',\n",
    "    yaxis_title='Accuracy en el conjunto de prueba',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "best_k = k_values[np.argmax(accuracies)]\n",
    "print(f\"\\nEl valor óptimo de k es: {best_k} con una precisión de {max(accuracies):.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2: Naive Bayes\n",
    "\n",
    "Ahora, aplicaremos el clasificador Naive Bayes Gaussiano. Esta variante es adecuada porque nuestras características son continuas y podemos asumir (ingenuamente) que siguen una distribución normal dentro de cada clase."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "# Inicializar y entrenar el clasificador Naive Bayes Gaussiano\n",
    "# Nota: Naive Bayes no es tan sensible al escalado, pero es buena práctica usar los datos escalados por consistencia.\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_gnb = gnb.predict(X_test_scaled)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"------ Resultados de Naive Bayes Gaussiano ------\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_gnb):.4f}\")\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred_gnb))\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred_gnb))\n",
    "end = time.time()\n",
    "print(f\"{end - start:.3f} segundos para entrenar el modelo Naive Bayes\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3: Perceptrón Multicapa (MLP)\n",
    "\n",
    "Finalmente, implementaremos una red neuronal simple. Usaremos `MLPClassifier` de Scikit-learn, que es una implementación eficiente y fácil de usar. Definiremos una arquitectura simple con una capa oculta."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "# Inicializar y entrenar el clasificador MLP\n",
    "# hidden_layer_sizes=(100,) significa una capa oculta con 100 neuronas.\n",
    "# max_iter=1000 para asegurar la convergencia.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_mlp = mlp.predict(X_test_scaled)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"------ Resultados del Perceptrón Multicapa (MLP) ------\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_mlp):.4f}\")\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred_mlp))\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred_mlp))\n",
    "end = time.time()\n",
    "print(f\"{end - start:.3f} segundos para entrenar el modelo MLP\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparación y Conclusiones\n",
    "\n",
    "En este caso particular, los tres modelos han obtenido una precisión muy alta, a menudo perfecta o casi perfecta en el conjunto de prueba. Esto se debe a que el dataset Wine es un problema relativamente \"fácil\" con clases bien separadas.\n",
    "\n",
    "* **k-NN** demostró ser muy efectivo, especialmente después de encontrar un buen valor para `k`.\n",
    "* **Naive Bayes** también funcionó excepcionalmente bien, lo que sugiere que, para este problema, el supuesto de independencia condicional no fue una limitación grave.\n",
    "* El **MLP** igualó el rendimiento de los otros modelos, mostrando su capacidad para resolver problemas de clasificación, aunque su entrenamiento es computacionalmente más costoso.\n",
    "\n",
    "En problemas del mundo real más complejos y con mayor superposición entre clases, las diferencias en el rendimiento de estos algoritmos suelen ser más pronunciadas. La elección del modelo dependerá de las características específicas del problema, la cantidad de datos disponibles y los recursos computacionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ejercicios Adicionales\n",
    "\n",
    "Para solidificar tu comprensión, aquí tienes 10 ejercicios para explorar por tu cuenta.\n",
    "\n",
    "1.  **Cambiar el Dataset:** Carga el dataset `load_breast_cancer` de `sklearn.datasets`. Es un problema de clasificación binaria. Repite el análisis completo (EDA, preprocesamiento, modelado y comparación) para este nuevo dataset. ¿Qué modelo funciona mejor aquí?\n",
    "\n",
    "2. **Arquitectura del MLP:** Experimenta con diferentes arquitecturas para el `MLPClassifier`. Prueba con más capas ocultas (ej. `hidden_layer_sizes=(100, 50,)`) o con diferente número de neuronas por capa. ¿Puedes mejorar la precisión obtenida?\n",
    "\n",
    "3. **Métricas de Distancia en k-NN:** El `KNeighborsClassifier` tiene un parámetro `metric`. Por defecto es `'minkowski'` (que con p=2 es la distancia Euclidiana). Prueba a cambiarlo a `'manhattan'` (Distancia de Manhattan). ¿Cambia el rendimiento del modelo?\n",
    "\n",
    "4. **Robustez del `train_test_split`:** Cambia el valor de `random_state` en la función `train_test_split`. Repite el entrenamiento y evaluación de los tres modelos. ¿Son los resultados de precisión exactamente los mismos? ¿Qué nos dice esto sobre la evaluación de modelos?\n",
    "\n",
    "5. **Comparar con Regresión Logística:** Como un modelo de base adicional, importa `LogisticRegression` de `sklearn.linear_model`. Entrénalo y evalúalo en el dataset Wine. ¿Cómo se compara su rendimiento con los tres modelos de esta clase?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
